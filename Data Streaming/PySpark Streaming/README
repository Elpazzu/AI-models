General information about Data Streaming with PySpark:
-----------------------------------------------------

Quite a lot of streaming data needs to be processed in real-time, such as Google Search results.

Spark Streaming is an extension of the core Spark API that enables scalable and fault-tolerant stream processing of live data streams.

Discretized Streams, or DStreams, represent a continuous stream of data. Here, either the data stream is received directly from any source or is received after we’ve done 
some processing on the original data.

The very first step of building a streaming application is to define the batch duration for the data resource from which we are collecting the data (i.e., If the batch 
duration is 2 seconds, then the data will be collected every 2 seconds and stored in an RDD).

RDD (Resilient Distributed Database) = collection of elements, that can be divided across multiple nodes in a cluster to run parallel processing. RDD is (i) fault tolerant as 
it can automatically recover from failures, (ii) immutable as we can create RDD once but can’t change it, and (iii) can host a large number of operations on it.

Accordingly, the chain of continuous series of these RDDs is a DStream which is immutable and can be used as a distributed dataset by Spark.

Spark maintains a history of all the transformations that we define on any data. So, whenever any fault occurs, it can retrace the path of transformations and regenerate the 
computed results again ==> Spark's computation can be quite expensive ==> Mitigations:
- CACHING: storing the computed/cached results temporarily to maintain the results of the transformations that are defined on the data. This way, there is no need to recompute 
those transformations again and again when any fault occurs + DStreams allow us to keep the streaming data in memory, which is helpful when we want to compute multiple operations 
on the same data
- CHECKPOINTING: Caching is extremely helpful when we use it properly but it requires a lot of memory (e.g., hundreds of machines with 128 GB of RAM). Checkpointing keeps the 
results of the transformed dataframes by saving the state of the running application from time to time on any reliable storage (e.g., HDFS). Issue is that it is slower and less 
flexible than caching. The transformation result depends upon previous transformation results and needs to be preserved in order to be used + metadata is also checkpointed 
(e.g., configuration used to create the streaming data, results of a set of DStream operations, etc.)

Shared variables in Spark:
Let’s assume a Spark application is running on 100 different clusters capturing Instagram images posted by people from different countries, and we need a count of a particular tag 
that was mentioned in a post ==> each cluster’s executor will calculate the results of the data present on it, But we need something that helps these clusters communicate so we 
can get the aggregated result ==> In Spark, we use shared variables for that purpose.

Accumulator variable in Spark:
Use cases like the number of times an error occurs, the number of blank logs, the number of times we receive a request from a particular country can be solved using accumulators.
The executor on each cluster sends data back to the driver process to update the values of the accumulator variables. Accumulators are applicable only to the operations that are 
associative and commutative (e.g., sum and maximum work, mean does not).

Broadcast variable in Spark:
It allows the programmer to keep a read-only variable cached on each machine. Usually, Spark automatically distributes broadcast variables using efficient broadcast algorithms 
but we can also define them if we have tasks that require the same data for multiple stages (e.g., location data, such as mappings of city names and ZIP codes, which are rather 
fixed variables that would be too expensive to send to clusters over and over again).

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Twitter Sentiment Analysis Model (cf. twitter-sentiment-analysis.py):
--------------------------------------------------------------------

The purpose of the model is to detect hate speeches in Tweets. For the sake of simplicity, we say a Tweet contains hate speech if it has a racist or sexist sentiment 
associated with it.

The dataset used for training contains 130,000 tweets labelled ‘1’ if racist/sexist and ‘0’ otherwise.

Setp-by-step process followed here:
i. Model Building -- a Logistic Regression Model pipeline to classify whether a tweet contains hate speech or not. My focus is not to build a very accurate classification model,
but rather to see how to use any model and return results on streaming data
ii. Initialize Spark Streaming Context -- define hostname and port number from where we get the streaming data
iii. Stream Data -- add the tweets from the netcat server from the defined port, then the Spark Streaming API receives the data after a specified time window
iv. Predict and Return Results -- pass the data into the machine learning pipeline and return the predicted sentiment from the model
