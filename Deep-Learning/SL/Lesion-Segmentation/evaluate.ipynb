{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %env SM_FRAMEWORK=tf.keras\n",
    "import zipfile, os, numpy as np, pickle, yaml, gc, tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import tensorflow_addons as tfa\n",
    "sys.path.append(\"..\")\n",
    "from model.resnet3d import Resnet3DBuilder\n",
    "from model.cnn_model import get_model\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "from segmentation_models import Unet\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "class_type = 0 # 0=NL, 1=AP"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_config(config_name):\n",
    "    with open(config_name) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "config = load_config(\"utils/model_config.yaml\")\n",
    "datatype='3.0T'\n",
    "nii_size = config['nii_size']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "S1 Testing Start!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# path test\n",
    "top_layer_path = config['top_layer_path']\n",
    "# S1 [img, msk]\n",
    "S1_img_stack = config['S1_img_stack']\n",
    "# S2 label\n",
    "S2_img_stack = config['S2_img_stack']\n",
    "# save path\n",
    "save_path = f'results_log/compose_model/all_NL-test_results_{datatype}'\n",
    "\n",
    "\n",
    "# S1 model weight path\n",
    "S1_weights=[config[\"S1_dense\"], config[\"S1_res\"], config[\"S1_vgg\"]]\n",
    "S1_backbone = ['densenet121', 'resnet50', 'vgg16']\n",
    "# S2 model weight path\n",
    "S2_weight=[config[\"S2_Resnet18\"], config[\"S2_ResNet50\"], config[\"S2_CNN\"]]\n",
    "S2_backbone =['resnet18', 'resnet50', 'cnn']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def S1_dataloader(valid_data='Mix', tune_type='test'):\n",
    "    if tune_type=='test':\n",
    "        img_layer_path = top_layer_path[0]\n",
    "        if valid_data == '3.0T':\n",
    "            # loading valida data 3.0T + 1.5T: image / masks\n",
    "            X_valid = np.load(img_layer_path +'/'+ S1_img_stack[0])\n",
    "            y_valid = np.load(img_layer_path +'/'+ S1_img_stack[1])\n",
    "\n",
    "    X_valid = np.reshape(X_valid, (X_valid.shape[0]*32,384,384,1))\n",
    "    y_valid = np.reshape(y_valid, (y_valid.shape[0]*32,384,384,1))\n",
    "    return X_valid.astype(np.float32), y_valid.astype(np.int8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def S1_model_loader(weight_path, backbone, mode):\n",
    "    S1_X_valid, S1_y_valid= S1_dataloader(valid_data=datatype, tune_type=mode)\n",
    "    print(f'S1 data shape: img {S1_X_valid.shape} msk {S1_y_valid.shape}')\n",
    "    model = Unet(backbone, encoder_weights=None, input_shape=(None, None, 1))\n",
    "    model.load_weights(weight_path)\n",
    "    Results = model.predict(S1_X_valid, batch_size=1, verbose=1)\n",
    "    return Results, S1_X_valid, S1_y_valid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def S2_model_loader(S1_pred_X, weight_path, backbone):\n",
    "    print(S1_pred_X.shape)\n",
    "    if 'resnet18' in backbone:\n",
    "        model = Resnet3DBuilder.build_resnet_18((32, nii_size, nii_size, 1), 1)\n",
    "    elif 'resnet50' in backbone:\n",
    "        model = Resnet3DBuilder.build_resnet_50((32, nii_size, nii_size, 1), 1)\n",
    "    elif 'cnn' in backbone:\n",
    "        model = get_model(depth=32, width=384, height=384, class_num=1, classification_layer='sigmoid')\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    if len(S1_pred_X.shape)==4 and backbone!='cnn':\n",
    "        S1_pred_X = np.expand_dims(S1_pred_X, axis=-1)\n",
    "    Results = model.predict(S1_pred_X, batch_size=1, verbose=1)\n",
    "    return Results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "if datatype=='3.0T':\n",
    "    data_n = 0\n",
    "S2_y_flatten = np.load(top_layer_path[0] + '/' + S2_img_stack[data_n]).flatten()\n",
    "S2_model_df = pd.DataFrame(S2_y_flatten, columns=['GT'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "S1_thresholds = 0.5\n",
    "S1_pred_stack=[]\n",
    "S2_pred_stack=[]\n",
    "# ----S1 model test 1 - 3----\n",
    "mode_list=['test']\n",
    "for d in mode_list:\n",
    "    print(f'Start model = {d}')\n",
    "    for i in range(3):\n",
    "        S1_pred, S1_X_valid, S1_y_valid = S1_model_loader(S1_weights[i], S1_backbone[i], d)\n",
    "        S1_pred = np.reshape(S1_pred, (S1_pred.shape[0]//32,32,384,384))\n",
    "        S1_y_valid = np.reshape(S1_y_valid, (S1_y_valid.shape[0]//32,32,384,384))\n",
    "        S1_X_valid = np.reshape(S1_X_valid, (S1_X_valid.shape[0]//32,32,384,384))\n",
    "        S1_pred = np.where(S1_pred > S1_thresholds, S1_X_valid, S1_X_valid*0)\n",
    "        S1_pred_stack.append(S1_pred)\n",
    "        # ----S2 model test 1 - 3----\n",
    "        for j in range(3):\n",
    "            print(S1_backbone[i], S2_backbone[j])\n",
    "            S2_pred = S2_model_loader(S1_pred, S2_weight[j][class_type], S2_backbone[j])\n",
    "            if d=='test':\n",
    "                S2_pred_stack.append(S2_pred)\n",
    "                S2_model_df[f'{S1_backbone[i]} + {S2_backbone[j]}'] = S2_pred.flatten()\n",
    "        del S1_pred, S2_pred\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "S2_model_df.to_csv(f'NL {datatype} all model.csv',index=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, roc_auc_score, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import sem\n",
    "sys.path.append(\"..\")\n",
    "from utils.visual_plt import ClassReport\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def CI(y_pred, y_true, optimal_th, score_type):\n",
    "    n_bootstraps = 1000\n",
    "    rng_seed = 42  # control reproducibility\n",
    "    bootstrapped_scores = []\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        if score_type=='acc':\n",
    "            score = accuracy_score(y_true[indices], y_pred[indices]>optimal_th)\n",
    "        elif score_type=='auc':\n",
    "            score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "    return confidence_lower, confidence_upper"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(30, 13))\n",
    "\n",
    "grid = plt.GridSpec(nrows=2, ncols=2, figure=fig)\n",
    "ax2 = plt.subplot(grid[0, 0])\n",
    "ax3 = plt.subplot(grid[0, 1])\n",
    "ax4 = plt.subplot(grid[1, 0:2])\n",
    "\n",
    "y_flatten = S2_model_df['GT']\n",
    "count=0\n",
    "result_table1 = []\n",
    "model_num = []\n",
    "next_ = 0\n",
    "optimal_th = 0.5\n",
    "\n",
    "color = ['tab:gray','tab:blue','tab:orange','tab:green','tab:red','tab:purple',\n",
    "         'tab:brown','tab:pink','tab:olive','tab:cyan','b','mediumvioletred']\n",
    "d_style = ['X','+','H','*','s','4','^','v','o','D','p','d']\n",
    "\n",
    "for i in S2_model_df:\n",
    "    p_flatten = S2_model_df[i]\n",
    "# -------------------------------plot AUROC and Cut-off Point-------------------\n",
    "    auc = roc_auc_score(y_flatten, p_flatten)\n",
    "    fpr, tpr, ths = roc_curve(y_flatten, p_flatten)\n",
    "# -------------------------------plot AUPRC-----------------------------\n",
    "    ap = average_precision_score(y_flatten, p_flatten)\n",
    "    pre, rec, _ = precision_recall_curve(y_flatten, p_flatten)\n",
    "\n",
    "    # ----table----\n",
    "    if i=='GT':\n",
    "        ax2.plot(fpr, tpr, lw=2, linestyle='dotted', color=color[count], label = f'GT')\n",
    "        ax3.step(rec, pre, lw=2, linestyle='dotted', label = f'GT', alpha=0.7)\n",
    "    elif i !='GT':\n",
    "        if next_+1<10:\n",
    "            model_ns = f'Model 0{next_+1}'\n",
    "            model_num.append(model_ns)\n",
    "        else:\n",
    "            model_ns = f'Model {next_+1}'\n",
    "            model_num.append(model_ns)\n",
    "        ax2.plot(fpr, tpr, lw=2, linestyle='dotted', color=color[count], label = f'{model_ns}')\n",
    "        ax3.step(rec, pre, lw=2, linestyle='dotted', label = f'{model_ns}', alpha=0.7)\n",
    "        result_table1.append([i])\n",
    "        p_flatten = S2_model_df[i]\n",
    "        cl1,cu1 =CI(p_flatten, y_flatten, optimal_th, score_type='auc')\n",
    "\n",
    "        cl2,cu2 =CI(p_flatten, y_flatten, optimal_th, score_type='acc')\n",
    "        y_proba_th = ((p_flatten > optimal_th).astype(np.int8))\n",
    "        acc = accuracy_score(y_flatten, y_proba_th)\n",
    "        CM = confusion_matrix(y_flatten, y_proba_th)\n",
    "        result_table1[next_].append(f'{auc:.3f}')\n",
    "        result_table1[next_].append(f'{cl1:.3f} - {cu1:.3f}')\n",
    "        result_table1[next_].append(f'{optimal_th:.3f}')\n",
    "        result_table1[next_].append(f'{acc:.3f}')\n",
    "        result_table1[next_].append(f'{cl2:.3f} - {cu2:.3f}')\n",
    "        result_table1[next_].append(f'{(CM[1,1]/(CM[1,1]+CM[1,0])):.3f}')\n",
    "        result_table1[next_].append(f'{(CM[0,0]/(CM[0,0]+CM[0,1])):.3f}')\n",
    "        result_table1[next_].append(f'{(CM[1,1]/(CM[1,1]+CM[0,1])):.3f}')\n",
    "        result_table1[next_].append(f'{ap:.3f}')\n",
    "    # ----table----\n",
    "        next_+=1\n",
    "    count+=1\n",
    "\n",
    "ax2.plot([0, 1], [0, 1], linestyle='--', lw=3, color='black', alpha=.7)\n",
    "ax2.legend(fontsize=10, loc='lower right')\n",
    "ax2.set_title(f'{datatype} Lacune Class - Test AUROC Plot', fontsize=18)\n",
    "ax2.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax2.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax2.set_xlim([-0.05, 1.05])\n",
    "ax2.set_ylim([-0.05, 1.05])\n",
    "\n",
    "ax3.legend(fontsize=10, loc='lower right')\n",
    "ax3.set_title(f'{datatype} Lacune Class - Test AUPRC Plot', fontsize=18)\n",
    "ax3.set_xlabel('Recall', fontsize=12)\n",
    "ax3.set_ylabel('Precision', fontsize=12)\n",
    "ax3.set_xlim([-0.05, 1.05])\n",
    "ax3.set_ylim([-0.05, 1.05])\n",
    "\n",
    "\n",
    "result_table1 = pd.DataFrame(result_table1, columns = ['Model Name', 'AUROC', 'AUC CI',\n",
    "                                                        'Threshold', 'Accuracy', 'Accuracy CI',\n",
    "                                                       'Sensitivity', 'Specificity', 'Precision','AUPRC'])\n",
    "\n",
    "ax4.axis('off')\n",
    "ax4.axis('tight')\n",
    "tab1 = ax4.table(cellText=result_table1.values, rowLabels = model_num, colLabels=result_table1.columns, cellLoc='center',loc='center')\n",
    "tab1.scale(1.1,1)\n",
    "tab1.auto_set_font_size(False)\n",
    "tab1.set_fontsize(14)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0)\n",
    "save_plt = './plot_results/'\n",
    "if not os.path.exists(save_plt):\n",
    "    os.makedirs(save_plt)\n",
    "plt.savefig(save_plt + f'{datatype} Lacune ALL model - Curve Plot .png', dpi=100)\n",
    "# plt.savefig(f'{save_path}/{datatype} Lacune ALL model - Curve Plot .jpg')\n",
    "plt.show()\n",
    "plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def heat_model(weight_path, backbone):\n",
    "#     if 'resnet18' in backbone:\n",
    "#         model = Resnet3DBuilder.build_resnet_18((32, nii_size, nii_size, 1), 1)\n",
    "#     elif 'resnet50' in backbone:\n",
    "#         model = Resnet3DBuilder.build_resnet_50((32, nii_size, nii_size, 1), 1)\n",
    "#     elif 'cnn' in backbone:\n",
    "#         model = get_model(depth=32, width=384, height=384, class_num=1, classification_layer='sigmoid')\n",
    "     \n",
    "#     model.load_weights(weight_path)\n",
    "#     return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# heatmap_weight=[S2_Resnet18, Only_ResNet50, Only_CNN]\n",
    "# heatmap_backbone=['resnet18', 'resnet50', 'cnn']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def last_conv_n(model_, backbone):\n",
    "#     count=0\n",
    "#     for i in model_.layers[::-1]:\n",
    "#         print(i.name)\n",
    "#         if 'cnn' in backbone:\n",
    "#             if 'pooling' in i.name and list(i.output_shape)[1]==1:\n",
    "#                 name = i.name\n",
    "#                 return name\n",
    "#                 break\n",
    "#         if '18' in backbone:\n",
    "#             # if 'conv' in i.name and count<1:\n",
    "#             #     count+=1\n",
    "#             # elif 'conv' in i.name and count==1:\n",
    "#             if 'conv' in i.name:\n",
    "#                 name = i.name\n",
    "#                 return name\n",
    "#                 break\n",
    "\n",
    "#         elif '50' in backbone:\n",
    "#             if 'add' in i.name:\n",
    "#                 name = i.name\n",
    "#                 return name\n",
    "#                 break\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# path_stack = ['T3_image_mask_path_valid.npy','T1_image_mask_path_valid.npy']\n",
    "# path = np.load(top_layer_path + '/' + path_stack[data_n])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from utils.heat_utils_2 import heat_map\n",
    "# from tqdm import tqdm\n",
    "# # save all heatmap\n",
    "# # all_heat = np.zeros((3,len(y_flatten), 384,384))\n",
    "# heat1=[]\n",
    "# heat2=[]\n",
    "# heat3=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import cv2\n",
    "# from PIL import Image as im\n",
    "# model1=heat_model(heatmap_weight[0],heatmap_backbone[0])\n",
    "# conv_name = last_conv_n(model1, heatmap_backbone[0])\n",
    "# X = S1_pred_stack[0]\n",
    "# # print('test data shape', X.shape)\n",
    "# for j in tqdm(range(len(y_flatten))):\n",
    "#     img_name = path[j].replace('../isXXXX_all_mask_and_image_check/3.0T_test/', '').replace('../isXXXX_all_mask_and_image_check/1.5T_test/','')[:6]\n",
    "#     hp = heat_map(model1, X[j]>0.5, y_flatten[j], img_name, 0.5, 'Circulation', conv_name)\n",
    "#     hp = cv2.resize(hp, (384,384), interpolation=cv2.INTER_LANCZOS4)\n",
    "#     hp = im.fromarray(hp)\n",
    "#     heat1.append(np.array(hp))\n",
    "#     # print(temp.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import nibabel as nib\n",
    "# from skimage import morphology\n",
    "# from scipy import ndimage\n",
    "# from PIL import Image\n",
    "# depth = 32\n",
    "# def resize_volume(img, size = 384,depth = 32):\n",
    "#     \"\"\"Resize across z-axis\"\"\"\n",
    "#     # Set the desired depth\n",
    "#     current_depth = img.shape[-1]\n",
    "#     current_width = img.shape[0]\n",
    "#     current_height = img.shape[1]\n",
    "#     img = ndimage.zoom(img, (size/current_height, size/current_width, 1), order=0)\n",
    "#     return img\n",
    "\n",
    "# def process_scan(path, size):\n",
    "# # get nib first channel\n",
    "#     image = nib.load(path)\n",
    "#     affine = image.header.get_best_affine()\n",
    "\n",
    "#     if len(image.shape) == 4:\n",
    "#         image = image.get_fdata()\n",
    "#         width,height,queue,_ = image.shape\n",
    "#         image = image[:,:,:,1]\n",
    "#         image = np.reshape(image,(width,height,queue))\n",
    "#     else:\n",
    "#         image = image.get_fdata()\n",
    "#         pass\n",
    "#     if affine[1, 1] > 0:\n",
    "#         image = ndimage.rotate(image, 90, reshape=False, mode=\"nearest\")\n",
    "#     if affine[1, 1] < 0:\n",
    "#         image = ndimage.rotate(image, -90, reshape=False, mode=\"nearest\")\n",
    "#     # print(affine)\n",
    "#     volume = resize_volume(image,size,depth)\n",
    "# #   add only black background mri image\n",
    "#     if volume.shape[2]!=depth:\n",
    "#         add_black_num = depth - volume.shape[2]\n",
    "#         volume = volume.transpose(2,0,1)\n",
    "#         for i in range(add_black_num):\n",
    "#             add_black_ = np.expand_dims(np.zeros((volume.shape[2],volume.shape[2])),axis=0)\n",
    "#             volume = np.concatenate((volume, add_black_), axis = 0)\n",
    "#         volume = volume.transpose(1,2,0)\n",
    "#     volume = volume.transpose(2,0,1)\n",
    "#     if affine[0, 0] < 0:\n",
    "#         for i in range(volume.shape[0]):\n",
    "#             volume[i,:,:] = np.fliplr(volume[i,:,:])\n",
    "#     return volume"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def get_original_mri(nii_name, valid_dtype):\n",
    "#     # print(nii_name)\n",
    "#     data_list = sorted(os.listdir(f'/ssd1/cnn/Classification/isXXXX_all_mask_and_image_check/{valid_dtype}_test'))\n",
    "#     for i in data_list:\n",
    "#         if nii_name in i and 'o' in i:\n",
    "#             # print(i)\n",
    "#             img = process_scan(f'/ssd1/cnn/Classification/isXXXX_all_mask_and_image_check/{valid_dtype}_test/'+i,384)\n",
    "#             # print(img.shape)\n",
    "#             return img\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import matplotlib.pyplot as pyplot\n",
    "# label_list = ['No-Lacune', 'Lacune']\n",
    "# # for p in range(1):"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from PIL import Image\n",
    "# def fig2npy(fig):\n",
    "#     fig.canvas.draw()\n",
    "#     w,h = fig.canvas.get_width_height()\n",
    "#     buf = np.frombuffer ( fig.canvas.tostring_argb(), dtype=np.uint8 )\n",
    "#     buf.shape = ( w, h,4 )\n",
    "#     buf = np.roll ( buf, 3, axis = 2 )\n",
    "#     return buf\n",
    "# def fig2img(fig):\n",
    "#     buf = fig2npy(fig)\n",
    "#     w, h, d  = buf.shape\n",
    "#     return Image.frombytes( \"RGBA\", ( w ,h ), buf.tostring( ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def plot_results(p, orig_img, gt_label, img_name):\n",
    "#     count=1\n",
    "#     gif_arr = []\n",
    "#     for i in range(32):\n",
    "#         if np.sum(S1_X_valid[p][i])!=0:\n",
    "#             fig, ax = plt.subplots(1,4, figsize = (13, 4))\n",
    "\n",
    "#             ax1 = ax[0]\n",
    "#             ax1.imshow(orig_img[i], cmap='gray')\n",
    "#             ax1.set_title(f'GT Img-{img_name} {label_list[gt_label]}')\n",
    "#             ax1.axis('off')\n",
    "\n",
    "#             ax2 = ax[1]\n",
    "#             ax2.imshow(S1_y_valid[p][i], cmap='gray')\n",
    "#             ax2.set_title(f'GT Seg - {label_list[gt_label]}')\n",
    "#             ax2.axis('off')\n",
    "\n",
    "#             ax3 = ax[2]\n",
    "#             ax3.imshow(S1_pred_stack[0][p][i]>.4, cmap='hot')\n",
    "#             ax3.set_title(f'Pred S1 - {label_list[gt_label]} ')\n",
    "#             ax3.axis('off')\n",
    "\n",
    "#             ax4 = ax[3]\n",
    "#             ax4.imshow(heat1[p], alpha=0.3, cmap='hot')\n",
    "#             ax4.imshow(orig_img[i], alpha=0.5, cmap='gray')\n",
    "#             ax4.set_title(f'Pred S1+S2 res18 - {label_list[gt_label]}')\n",
    "#             ax4.axis('off')\n",
    "#             fig.tight_layout()\n",
    "#             plt.savefig(save_path + '/' + img_name+ '/' + f'{img_name}-{count}.jpg')\n",
    "\n",
    "#             count+=1\n",
    "#             im = fig2img(fig)\n",
    "#             gif_arr.append(im)\n",
    "\n",
    "#             plt.cla()\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#     im.save(save_path + '/' + img_name+ '/' + f'{img_name}.gif', save_all=True, append_images=[i for i in gif_arr], optimize=False, duration=500, loop=0)\n",
    "#     del im\n",
    "#     # ax.close('all')\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for p in tqdm(range(S1_X_valid.shape[0])):\n",
    "# # for p in tqdm(range(1):\n",
    "#     gt_label = y_flatten[p]\n",
    "\n",
    "#     img_name = path[p].replace('../isXXXX_all_mask_and_image_check/3.0T_test/', '').replace('../isXXXX_all_mask_and_image_check/1.5T_test/','')[:6]\n",
    "#     orig_img = get_original_mri(img_name, datatype)\n",
    "#      # heatmap [GT, Seg, pred1, S2 res18 h, only res50 h, only cnn h ]\n",
    "#     if not os.path.exists(save_path + '/' + img_name):\n",
    "#         os.makedirs(save_path + '/' + img_name)\n",
    "#     plot_results(p, orig_img ,gt_label, img_name)\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('MRI_tf2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "5d33ac8ce81c8da01985ba1576671d92ac976b7a4615b42eb65ecef4f329b894"
   }
  },
  "interpreter": {
   "hash": "cd25b859a36183113c4e26a1f0a9aa602f9d8818daf3d23240ea27bf554d7c6d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
